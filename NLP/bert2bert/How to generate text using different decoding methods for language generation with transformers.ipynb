{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def0a0be",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In recent years, there has been an increasing interest in open-ended language generation thanks to the rist of large transformer-based lanugage models trained on millions of webpages.\n",
    "\n",
    "Besides the improved transformer architecture and massive unsupervised training data, better decoding methods have also played an important role.\n",
    "\n",
    "All of the following functionalities can be used for auto-regressive language generation. In short, auto-regreesive language generation is based on the assumption that the probability distribution of a word sequence can be decomposed into the product of conditional next word distributions:\n",
    "\n",
    "\n",
    "$$P(w_{1:T}\\mid W_0) = \\prod_{t=1}^T P(w_t \\mid w_{1:t-1}, W_0), \\text{ with } w_{1:0} = \\emptyset$$\n",
    "\n",
    "and $W_0$ being the initial context word sequence. The length $T$ of the word sequence is usually determined on-the-fly and corresponds to the timestep $t=T$ the EOS token is generated from $P(w_t \\mid w_{1:t-1}, W_0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7542b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "145d2d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb39eb12adc47f68b5a31b672e656bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412e2467e7124abd8969847e3a504f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada807df2c23435fa6797fd0c01406a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb3430ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50256\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aa886b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bea8f44e67404c852347fe140a6c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id, is_decoder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f58c66c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2437,  389,  345,   30]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"How are you?\", return_tensors='pt')\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6cf5832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "----------------------------------------------------------------------------------------------------\n",
      "How are you?\n",
      "\n",
      "I've been working on this project for a while now, and I'm really excited to share it with you. It's been a long time coming, but it's finally here. I hope you enjoy it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(input_ids,\n",
    "                             max_length=50,\n",
    "                             num_beams=5,\n",
    "                             no_repeat_ngram_size=2,\n",
    "                             early_stopping=True)\n",
    "\n",
    "results = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Output: \\n\" + 100 * '-')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da64b773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2437,  389,  345,   30,  198,  198,   40, 1053,  587, 1762,  319,  428,\n",
       "         1628,  329,  257,  981,  783,   11,  290,  314, 1101, 1107, 6568,  284,\n",
       "         2648,  340,  351,  345,   13,  632,  338,  587,  257,  890,  640, 2406,\n",
       "           11,  475,  340,  338, 3443,  994,   13,  314, 2911,  345, 2883,  340,\n",
       "           13,  198]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b000b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
